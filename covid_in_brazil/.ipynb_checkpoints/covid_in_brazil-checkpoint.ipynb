{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "899bb7ef-75df-410a-a4d9-4c7324d9f91c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px \n",
    "import seaborn as sns\n",
    "import unidecode, re\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# ImportError: cannot import name '_print_elapsed_time' from 'sklearn.utils'\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix, classification_report, roc_auc_score\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from scipy import *\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pycaret.classification import *\n",
    "my_font = dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=18,\n",
    "            color=\"Black\",\n",
    "            variant=\"small-caps\",\n",
    ") \n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df_test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1117fe3-629d-448e-9dba-e524a86c79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('SG_UF').size().reset_index(name='count').sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dee717c5-416e-4682-afb0-2ab7c8536a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.histogram(\n",
    "#     df.groupby(['SG_UF','OBESIDADE']).size().reset_index(name='count').sort_values(by='count', ascending=False),\n",
    "#     x='SG_UF',\n",
    "#     y='count',\n",
    "#     color='SG_UF')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91ad7d82-7c49-4b3c-ac30-4104d8b7f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x = df.groupby('GARGANTA').size().reset_index(name='count').sort_values(by='count', ascending=False)\n",
    "\n",
    "# px.histogram(\n",
    "#      x,\n",
    "#      x='GARGANTA',\n",
    "#      y='count',\n",
    "#      color='GARGANTA')\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "989351f9-03dd-435e-a6de-90aa510d6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.histogram(\n",
    "#     df.groupby(['SG_UF','CS_SEXO']).size().reset_index(name='count').sort_values(by='count', ascending=False),\n",
    "#     x='SG_UF',\n",
    "#     y='count',\n",
    "#     color='SG_UF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8501e1b1-75e9-4d8a-aea5-992b8054e523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = df.select_dtypes(['number']).drop(columns=['EVOLUCAO'])\n",
    "# y_train = df['EVOLUCAO']\n",
    "\n",
    "# X_test_sub = df_test.select_dtypes(['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c76f511-b069-476c-8e59-7f84ebbcb532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test= train_test_split(X_train, y_train, test_size = .1, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c6a6a09-d1da-48b2-b047-1f2965bcbd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catb = CatBoostClassifier(\n",
    "#     iterations=100,      \n",
    "#     learning_rate=0.1,   \n",
    "#     depth=6,              \n",
    "#     verbose=0             \n",
    "# )\n",
    "\n",
    "# catb.fit(X_train, y_train)\n",
    "\n",
    "# preds = catb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dbf3c7c-fe9d-4fcf-9201-63e2046752a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# catboost_accuracy = accuracy_score(y_test, preds)\n",
    "# print(f\"CatBoost's acurracy: {catboost_accuracy*100:.2f}%\")\n",
    "\n",
    "# print(\"\\nClassification report\")\n",
    "# print(classification_report(y_test, preds))\n",
    "\n",
    "# cm = confusion_matrix(y_test, preds)\n",
    "# fig = px.imshow(cm, text_auto=True).update_layout(title={\"text\": \"CatBoost's Confusion Matrix\"}, font=my_font).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df55883f-a1ab-4986-bb7b-5a5544b02480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred = catb.predict_proba(X_test_sub)[:,1] # chances of death, class: 1.0\n",
    "\n",
    "# pd.DataFrame(np.round(test_pred)).reset_index().to_csv('results/submission_catboost.csv', header=['ID', 'EVOLUCAO'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9756dd85-d895-4af5-87ed-5b6613d17164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightGBM = lgb.LGBMClassifier(random_state=23)\n",
    "\n",
    "# lightGBM.fit(X_train, y_train)\n",
    "\n",
    "# preds = lightGBM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3be46790-eeec-4d86-99a5-d920a1afe143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = lightGBM.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# print(f\"LightGBM acurracy: {accuracy*100:.2f}%\")\n",
    "# print(\"\\nClassification report\")\n",
    "# print(classification_report(y_test, preds))\n",
    "\n",
    "# cm = confusion_matrix(y_test, preds)\n",
    "# fig = px.imshow(cm, text_auto=True).update_layout(title={\"text\": \"LightGBM's Confusion Matrix\"}, font=my_font).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ff6cca4-6e33-4334-a643-b60c208cd611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred = lightGBM.predict_proba(X_test_sub)[:,1] # chances of death, class: 1.0\n",
    "\n",
    "# pd.DataFrame(np.round(test_pred)).reset_index().to_csv('results/submission_light_gbm.csv', header=['ID', 'EVOLUCAO'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68aa8664-7733-415d-919d-e98664d8692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf = RandomForestClassifier()\n",
    "\n",
    "# rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c47202c0-7cf6-49ff-a904-4ea5875bedc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = rf.predict(X_test)\n",
    "# accuracy = rf.score(X_test, y_test)\n",
    "\n",
    "# print(f\"Accuracy: {accuracy*100:.2f}\")\n",
    "# print(\"\\nClassification report\")\n",
    "# print(classification_report(y_test, preds))\n",
    "\n",
    "# cm = confusion_matrix(y_test, preds)\n",
    "# fig = px.imshow(cm, text_auto=True).update_layout(title={\"text\": \"Random Forest's Confusion Matrix\"}, font=my_font).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbe23a96-fd3b-48a7-a2bb-afce82adf48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg = XGBClassifier()\n",
    "# xg.fit(X_train, y_train)\n",
    "# preds = xg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25280b6c-47ea-4934-9575-0cd7c0448957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = xg.score(X_test, y_test)\n",
    "\n",
    "# print(f\"Accuracy: {accuracy*100:.2f}\")\n",
    "# print(\"\\nClassification report\")\n",
    "# print(classification_report(y_test, preds))\n",
    "\n",
    "# cm = confusion_matrix(y_test, preds)\n",
    "# fig = px.imshow(cm, text_auto=True).update_layout(title={\"text\": \"XGBoost's Confusion Matrix\"}, font=my_font).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71c153d9-a726-44ca-9610-e369702f1396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pred = xg.predict_proba(X_test_sub)[:,1] # chances of death, class: 1.0\n",
    "\n",
    "# pd.DataFrame(np.round(test_pred)).reset_index().to_csv('submission_xg.csv', header=['ID', 'EVOLUCAO'], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63729001-cbdb-43d9-91d7-d02022a72fad",
   "metadata": {},
   "source": [
    "# Now we can try to treat this dataset\n",
    "- Let us start by checking what columns have more missing values\n",
    "- Then we can drop rows with more that 90% of the data NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d474efa6-3809-4c40-9283-bf6f08e75279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.histogram(df.isna().sum().reset_index(name='count').sort_values(by='count', ascending=False),\n",
    "#             x='index', y='count', color='count', color_discrete_sequence= px.colors.sequential.Plasma_r,\n",
    "#              title=\"Most frequent columns with missing values\").update_layout(font = my_font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90bdaf39-0962-459a-9f6a-b2e609075aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df.isna().sum().reset_index(name='count').sort_values(by='count', ascending=False)\n",
    "# x['pecentage_of_missing_data'] = (x['count'] / len(df))*100\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f9c7468-fba1-456c-85b9-0e5aa23225f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.histogram(df.isna().sum().reset_index(name='count').sort_values(by='count', ascending=True).head(20),\n",
    "#             x='index', y='count', color='count', color_discrete_sequence= px.colors.sequential.Plasma_r,\n",
    "#              title=\"Less frequent columns with missing values\").update_layout(font = my_font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7213011-e3d1-4c32-b6d7-643e897a7054",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = df.isnull().sum(axis=1)\n",
    "thresh = 27\n",
    "df_no_nulls = df[missing_counts < thresh]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9bf4b1-a018-4ec8-93ed-16d9b7e450a3",
   "metadata": {},
   "source": [
    "### Note: You cannot just filter out all columns with ANY missing values\n",
    " - The accuracy of all models pretty much drops drastically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84dd760b-7d8b-45f1-8dab-2a7916f9912f",
   "metadata": {},
   "source": [
    "### Checking correlation between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5aaf96cd-72cd-4a12-8f74-e5d825e5d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 12))\n",
    "# sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='viridis', fmt=\".1f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b939f5ea-f09d-4a83-b25c-f6fea4dec5f1",
   "metadata": {},
   "source": [
    "## Frist, we can create a total_comorbities columns to represent the total amount of comordities one has.\n",
    "    - We will separate it in chronic and temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "867f63d7-c648-4fb3-b84e-2b47633ef918",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_nulls['total_chronic_cormodity'] = ((df_no_nulls[[\"OBESIDADE\", \n",
    "                                                        \"RENAL\", \n",
    "                                                        \"CARDIOPATI\",\n",
    "                                                        \"IMUNODEPRE\", \n",
    "                                                        \"DIABETES\", \n",
    "                                                        \"PNEUMOPATI\",\n",
    "                                                        \"HEPATICA\",\n",
    "                                                        \"SIND_DOWN\"]] == 1.0).sum(axis=1))\n",
    "\n",
    "df_no_nulls['total_temporary_cormodity'] = (df_no_nulls[[\"FEBRE\",\n",
    "                                                        \"TOSSE\",\n",
    "                                                        \"PUERPERA\",\n",
    "                                                        \"GARGANTA\",\n",
    "                                                        \"DESC_RESP\",\n",
    "                                                        \"DIARREIA\",\n",
    "                                                        \"VOMITO\",\n",
    "                                                        \"FADIGA\",\n",
    "                                                        \"SATURACAO\",\n",
    "                                                        \"DISPNEIA\"]]== 1.0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d01d473-4e05-492d-afc3-7a18cee97f63",
   "metadata": {},
   "source": [
    "# Creating a function to handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7cf1a338-2173-4786-8e27-9d315d7bf0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self, dataframe):\n",
    "        self.df = dataframe.copy()\n",
    "    \n",
    "    def fill_rows_with_ints(self, columns_to_fill, missing_value=0):\n",
    "        for col in columns_to_fill:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = self.df[col].fillna(missing_value)\n",
    "                self.df[col] = self.df[col].astype(int)\n",
    "        return self.df\n",
    "    \n",
    "    def fill_null_rows(self, columns_to_fill, missing_value):\n",
    "        for col in columns_to_fill:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = self.df[col].fillna(missing_value)\n",
    "                self.df[col] = self.df[col].astype(str)\n",
    "\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "2f5efd63-9707-4ebe-b6f3-9d181d9a66f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling nulls with 9 and converting everything to category\n",
    "\n",
    "preprocessor = DataPreprocessor(df_no_nulls)\n",
    "preprocessor_test = DataPreprocessor(df_test)\n",
    "\n",
    "columns_to_fill = df_no_nulls.select_dtypes(['float']).columns.tolist()\n",
    "\n",
    "processed_df = preprocessor.fill_rows_with_ints(columns_to_fill, missing_value=9)\n",
    "processed_df_test = preprocessor_test.fill_rows_with_ints(columns_to_fill, missing_value=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4a48472a-b0e9-4e16-984a-cfeb36210742",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_fill = [\n",
    "                   \"OBESIDADE\", \n",
    "                   \"RENAL\", \n",
    "                   \"CARDIOPATI\",\n",
    "                   \"IMUNODEPRE\", \n",
    "                   \"DIABETES\", \n",
    "                   \"PNEUMOPATI\",\n",
    "                   \"HEPATICA\",\n",
    "                   \"FEBRE\",\n",
    "                   \"TOSSE\",\n",
    "                   \"GARGANTA\",\n",
    "                   \"DESC_RESP\",\n",
    "                   \"DIARREIA\",\n",
    "                   \"VOMITO\",\n",
    "                   \"FADIGA\",\n",
    "                   \"SATURACAO\",\n",
    "                   \"DISPNEIA\",\n",
    "                   \"CS_RACA\",\n",
    "                   \"CS_ZONA\",\n",
    "                   \"VACINA\",\n",
    "                   \"CS_ESCOL_N\",\n",
    "                   \"FATOR_RISC\",\n",
    "                   \"SIND_DOWN\",\n",
    "                   \"CO_RG_RESI\",\n",
    "                   \"PUERPERA\",\n",
    "                   \"CS_SEXO\",\n",
    "                   \"SG_UF\",\n",
    "                   \"EVOLUCAO\",\n",
    "                   \"CS_GESTANT\"\n",
    "                  ] # 22 columns \n",
    "\n",
    "preprocessor = DataPreprocessor(processed_df)\n",
    "preprocessor_test = DataPreprocessor(processed_df_test)\n",
    "\n",
    "df_2 = preprocessor.fill_null_rows(columns_to_fill, 9)\n",
    "\n",
    "\n",
    "df_test_copy = preprocessor_test.fill_null_rows(columns_to_fill, 9)\n",
    "\n",
    "df_2.drop(columns={\"DT_NOTIFIC\", \"ID_MN_RESI\",\"OBES_IMC\", \"CO_RG_RESI\"}, inplace=True)\n",
    "df_test_copy.drop(columns={\"DT_NOTIFIC\", \"ID_MN_RESI\",\"OBES_IMC\", \"CO_RG_RESI\"}, inplace=True)\n",
    "\n",
    "\n",
    "X = df_2.drop(columns={'EVOLUCAO'})\n",
    "y = df_2['EVOLUCAO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "05249382-ecc7-4fb0-91af-1c4155095de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_2.groupby(['EVOLUCAO']).size()\n",
    "# We have an imbalanced dataset\n",
    "# from sklearn.preprocessing import LabelEncoder, TargetEncoder\n",
    "# from category_encoders import TargetEncoder\n",
    "# from pycaret.classification import *\n",
    "\n",
    "# df_pycaret = df_2.copy()\n",
    "# df_pycaret.drop(columns={\"DT_NOTIFIC\", \"ID_MN_RESI\",\"OBES_IMC\", \"CO_RG_RESI\"}, inplace=True) # feature_selection = True\n",
    "\n",
    "\n",
    "# feats = df_pycaret.select_dtypes(['category']).columns.tolist()\n",
    "# feats.remove('EVOLUCAO')\n",
    "\n",
    "# s = setup(df_pycaret, \n",
    "#           target='EVOLUCAO', \n",
    "#           session_id=123,\n",
    "#           #categorical_features = feats, \n",
    "#           encoding_method = LabelEncoder,\n",
    "#          )\n",
    "#           #fix_imbalance = True,\n",
    "#           #feature_selection = True\n",
    "# # List of model IDs to include\n",
    "# # You can find the list of all available models by using the models() function\n",
    "# models_to_include = ['catboost', 'xgboost', 'lightgbm', 'svm']\n",
    "\n",
    "# # Compare a specific set of models (Logistic Regression, Decision Tree, Random Forest)\n",
    "# best_models_subset1 = compare_models(include=models_to_include)\n",
    "\n",
    "# # The function returns the best performing model from the specified subset based on the default metric (e.g., 'Accuracy' for classification)\n",
    "# print(best_models_subset1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb127f1-4b0c-4c4e-9fc2-4a88233887b1",
   "metadata": {},
   "source": [
    "## Since we got an imbalanced dataset, let us oversample it with SMOTE and ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a8d5a77d-79d2-45eb-bfa1-bea4b3ae58f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = pd.DataFrame(y)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.15, random_state=32)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.19, random_state=32)\n",
    "# Note: 0.25 * 0.8 = 0.20, so overall 60/20/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c537ef85-f477-4ed0-bf6d-a8878f6b146c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5868e1f5-956c-4a38-aec6-36672d6d54d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 498320 entries, 0 to 498319\n",
      "Data columns (total 29 columns):\n",
      " #   Column                     Non-Null Count   Dtype \n",
      "---  ------                     --------------   ----- \n",
      " 0   CS_SEXO                    498320 non-null  object\n",
      " 1   CS_ZONA                    498320 non-null  object\n",
      " 2   NU_IDADE_N                 498320 non-null  int64 \n",
      " 3   CS_ESCOL_N                 498320 non-null  object\n",
      " 4   CS_RACA                    498320 non-null  object\n",
      " 5   SG_UF                      498320 non-null  object\n",
      " 6   CS_GESTANT                 498320 non-null  object\n",
      " 7   PUERPERA                   498320 non-null  object\n",
      " 8   DIABETES                   498320 non-null  object\n",
      " 9   PNEUMOPATI                 498320 non-null  object\n",
      " 10  IMUNODEPRE                 498320 non-null  object\n",
      " 11  RENAL                      498320 non-null  object\n",
      " 12  OBESIDADE                  498320 non-null  object\n",
      " 13  CARDIOPATI                 498320 non-null  object\n",
      " 14  SIND_DOWN                  498320 non-null  object\n",
      " 15  HEPATICA                   498320 non-null  object\n",
      " 16  FATOR_RISC                 498320 non-null  object\n",
      " 17  FEBRE                      498320 non-null  object\n",
      " 18  TOSSE                      498320 non-null  object\n",
      " 19  GARGANTA                   498320 non-null  object\n",
      " 20  DESC_RESP                  498320 non-null  object\n",
      " 21  DIARREIA                   498320 non-null  object\n",
      " 22  VOMITO                     498320 non-null  object\n",
      " 23  FADIGA                     498320 non-null  object\n",
      " 24  SATURACAO                  498320 non-null  object\n",
      " 25  DISPNEIA                   498320 non-null  object\n",
      " 26  VACINA                     498320 non-null  object\n",
      " 27  total_chronic_cormodity    498320 non-null  int64 \n",
      " 28  total_temporary_cormodity  498320 non-null  int64 \n",
      "dtypes: int64(3), object(26)\n",
      "memory usage: 110.3+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde769c-c4f3-4ce3-aa5a-00acbff768f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = [X.columns.get_loc(c) for c in X.select_dtypes(['object']).columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd4bb159-8dc4-44b2-8f9d-5bf5e3c563d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SMOTENC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# cat_feats = X.select_dtypes(['category']).columns\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m sm = \u001b[43mSMOTENC\u001b[49m(random_state=\u001b[32m32\u001b[39m, categorical_features=cat_feats)\n\u001b[32m      4\u001b[39m X_resample, y_resample = sm.fit_resample(X_train, y_train)\n",
      "\u001b[31mNameError\u001b[39m: name 'SMOTENC' is not defined"
     ]
    }
   ],
   "source": [
    "# cat_feats = X.select_dtypes(['category']).columns\n",
    "\n",
    "sm = SMOTENC(random_state=32, categorical_features=cat_feats)\n",
    "X_resample, y_resample = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fefa5b-3667-4fec-b0b0-0c55daa9d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM uses integer column indices for categorical features\n",
    "cat_features = [X.columns.get_loc(c) for c in X.select_dtypes(['category']).columns]\n",
    "\n",
    "params = {\n",
    "    'n_estimators': 150,          # equivalent to iterations\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 7,\n",
    "    'random_state': 32,\n",
    "    'extra_trees': True,\n",
    "    'metric': 'binary_logloss',\n",
    "    'min_data_in_leaf': 1000,\n",
    "    'num_leaves': 30,\n",
    "    'colsample_bytree': 0.7,       # similar to rsm\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 6,               # L2 regularization\n",
    "    'bagging_fraction': 0.7,       # subsample ratio (use with bagging_freq)\n",
    "    'bagging_freq': 1,\n",
    "    'metric': 'TotalF1',     # default eval metric\n",
    "    'verbose': -1,\n",
    "    'lambda_l1': 1.0,\n",
    "        #'early_stopping_rounds':10,\n",
    "    'verbose': -1\n",
    "\n",
    "}\n",
    "\n",
    "lgbm = lgb.LGBMClassifier(**params)\n",
    "\n",
    "# Fit model\n",
    "lgbm.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    eval_names=['validation'],\n",
    "    eval_metric='binary_logloss'\n",
    "    # categorical_feature=cat_features,\n",
    "    # callbacks=[\n",
    "    #     lgb.early_stopping(stopping_rounds=50),\n",
    "    #     lgb.log_evaluation(period=50)\n",
    "    # ]\n",
    ")\n",
    "\n",
    "# Prediction\n",
    "y_pred = lgbm.predict_proba(X_valid)[:, 1]  # prob for class 1\n",
    "print(\"Validation AUC:\", roc_auc_score(y_valid, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4733d61-870b-4b12-9ae0-6d78f5281b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# SHAP analysis\n",
    "explainer = shap.TreeExplainer(lgbm)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test, feature_names=X_train.columns, plot_type=\"bar\")\n",
    "shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "# put into DataFrame for readability\n",
    "shap_importance_df = pd.DataFrame({\n",
    "    \"feature\": X_test.columns,\n",
    "    \"importance\": shap_importance\n",
    "}).sort_values(by=\"importance\", ascending=True)\n",
    "\n",
    "print(shap_importance_df.head(10))   # lowest 10 features\n",
    "# Drop low-impact features\n",
    "# low_impact_features = [...]  # your list\n",
    "# X_train_reduced = X_train.drop(columns=low_impact_features)\n",
    "# X_valid_reduced = X_valid.drop(columns=low_impact_features)\n",
    "\n",
    "# # Update categorical feature indices\n",
    "# cat_features_reduced = [X_train_reduced.columns.get_loc(f) for f in cat_features if f not in low_impact_features]\n",
    "\n",
    "# # Create LightGBM datasets\n",
    "# train_data = lgb.Dataset(X_train_reduced, label=y_train, categorical_feature=cat_features_reduced)\n",
    "# valid_data = lgb.Dataset(X_valid_reduced, label=y_valid, categorical_feature=cat_features_reduced, reference=train_data)\n",
    "\n",
    "# # Train LightGBM\n",
    "# model = lgb.train(\n",
    "#     params,\n",
    "#     train_data,\n",
    "#     valid_sets=[train_data, valid_data],\n",
    "#     valid_names=[\"train\", \"valid\"],\n",
    "#     num_boost_round=2000,\n",
    "#     early_stopping_rounds=100\n",
    "# )\n",
    "# y_pred = model.predict_proba(X_valid)[:, 1]  # prob for class 1\n",
    "# print(\"Validation AUC:\", roc_auc_score(y_valid, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e04a720-4646-4bc9-b3fb-62ca43eff2c5",
   "metadata": {},
   "source": [
    "### Now we will drop out unimportant feaures like SIND_DOWN    0.002544\n",
    "###                 PUERPERA    0.005949\n",
    "###                     CS_ZONA    0.007252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8204eb94-67e5-4df8-b6c1-bf362a6eba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.drop(columns={\"SIND_DOWN\", \"PUERPERA\", \"VOMITO\",\"HEPATICA\"}, inplace=True)\n",
    "df_test_copy.drop(columns={\"SIND_DOWN\", \"PUERPERA\", \"VOMITO\",\"HEPATICA\"}, inplace=True)\n",
    "\n",
    "\n",
    "X = df_2.drop(columns={'EVOLUCAO'})\n",
    "y = df_2['EVOLUCAO']\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.15, random_state=32)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.19, random_state=32)\n",
    "# Note: 0.25 * 0.8 = 0.20, so overall 60/20/20\n",
    "\n",
    "\n",
    "\n",
    "lgbm.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    eval_names=['validation'],\n",
    "    eval_metric='binary_logloss'\n",
    "    # categorical_feature=cat_features,\n",
    "    # callbacks=[\n",
    "    #     lgb.early_stopping(stopping_rounds=50),\n",
    "    #     lgb.log_evaluation(period=50)\n",
    "    # ]\n",
    ")\n",
    "\n",
    "# Prediction\n",
    "y_pred = lgbm.predict_proba(X_valid)[:, 1]  # prob for class 1\n",
    "print(\"Validation AUC:\", roc_auc_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f5c5d1-55a0-411d-a1b2-bb8b4e336319",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.15, random_state=32)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.19, random_state=32)\n",
    "# Note: 0.25 * 0.8 = 0.20, so overall 60/20/20\n",
    "\n",
    "\n",
    "cat_features = X.select_dtypes(['category']).columns.tolist()\n",
    "params = {\n",
    "    'iterations':300,\n",
    "    'learning_rate':0.05,\n",
    "    'depth':7,\n",
    "    'eval_metric':'TotalF1',\n",
    "    'random_seed':32,\n",
    "    'rsm': 0.7,\n",
    "    'early_stopping_rounds': 10,\n",
    "    'verbose': 50,\n",
    "    'loss_function': 'MultiClass',\n",
    "    'use_best_model': True,\n",
    "    'l2_leaf_reg': 6,      # default 3, increase to reduce overfit\n",
    "    'random_strength': 1.5,  # adds noise to splits\n",
    "    'bagging_temperature': 2  \n",
    "   #  'num_leaves': 50\n",
    "}\n",
    "ctb = CatBoostClassifier(\n",
    "  **params\n",
    ")\n",
    "\n",
    "ctb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_valid, y_valid),\n",
    "    cat_features=cat_features,\n",
    ")\n",
    "\n",
    "y_pred = ctb.predict_proba(X_valid)[:, 1]\n",
    "print(\"Validation AUC:\", roc_auc_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3195abce-df3d-49dc-b0b6-f40fd1e954a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ctb.predict(X_test)\n",
    "\n",
    "accuracy = ctb.score(X_test, y_test)\n",
    "\n",
    "\n",
    "print(f\"ctb acurracy: {accuracy*100:.2f}%\")\n",
    "print(\"\\nClassification report\")\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "fig = px.imshow(cm, text_auto=True).update_layout(title={\"text\": \"CatBoost's Confusion Matrix\"}, font=my_font).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4889b03-a1cd-4ba0-a7c5-7161326d267e",
   "metadata": {},
   "source": [
    "## Grid searching for the best params "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efc4bc1a-272e-46d5-a1b6-883bdbe6cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'depth': [4, 6, 8],               # tree depth\n",
    "#     'learning_rate': [0.01, 0.03, 0.05],  # step size\n",
    "#     'l2_leaf_reg': [3, 5, 7],         # regularization\n",
    "#     'bagging_temperature': [0, 0.5, 1], # randomness in bagging\n",
    "#     'rsm': [0.7, 0.8, 1.0]            # fraction of features per tree\n",
    "# }\n",
    "\n",
    "\n",
    "# ctb = CatBoostClassifier(\n",
    "#     iterations=500,\n",
    "#     loss_function='Logloss',\n",
    "#     eval_metric='TotalF1',\n",
    "#     cat_features=cat_features,\n",
    "#     verbose=0\n",
    "# )\n",
    "\n",
    "# randomized_search_result  = ctb.randomized_search(\n",
    "#     param_grid,\n",
    "#     X = X,\n",
    "#     y= y,\n",
    "#     plot=True\n",
    "# )\n",
    "\n",
    "# # rand_search.fit(X_train, y_train)\n",
    "# # print(\"Best params:\", rand_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d56a4c1-a260-4f9c-aaff-0055dde386f0",
   "metadata": {},
   "source": [
    "## Cross-validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89b627c7-08b5-4207-9625-3fb6ad158147",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m pool = Pool(data=\u001b[43mX\u001b[49m, label=y, cat_features=cat_features)\n\u001b[32m      3\u001b[39m cv_results = cv(\n\u001b[32m      4\u001b[39m     pool=pool,\n\u001b[32m      5\u001b[39m     params=params,\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     verbose_eval=\u001b[32m50\u001b[39m\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m best_iter = cv_results[\u001b[33m'\u001b[39m\u001b[33mtest-TotalF1-mean\u001b[39m\u001b[33m'\u001b[39m].idxmax()\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "pool = Pool(data=X, label=y, cat_features=cat_features)\n",
    "\n",
    "cv_results = cv(\n",
    "    pool=pool,\n",
    "    params=params,\n",
    "    fold_count=5,               # number of folds\n",
    "    shuffle=True,               # shuffle data before splitting\n",
    "    partition_random_seed=42,   # reproducibility\n",
    "    early_stopping_rounds=50,   # stop if no improvement\n",
    "    verbose_eval=50\n",
    ")\n",
    "\n",
    "best_iter = cv_results['test-TotalF1-mean'].idxmax()\n",
    "print(\"Best iteration:\", best_iter)\n",
    "print(\"Best CV F1:\", cv_results['test-TotalF1-mean'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb5c721d-4b17-4a0d-bea8-d3afe3c78069",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m interaction_matrix = \u001b[43mmodel\u001b[49m.get_feature_importance(data=train_pool, \u001b[38;5;28mtype\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mFeatureImportance\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# feature_names = X_train.columns\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# interaction_df = pd.DataFrame(interaction_matrix, index=X_train.columns, columns=X_train.columns)\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# print(interaction_df)\u001b[39;00m\n\u001b[32m      7\u001b[39m interaction_matrix\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "interaction_matrix = model.get_feature_importance(data=train_pool, type='FeatureImportance')\n",
    "# feature_names = X_train.columns\n",
    "\n",
    "\n",
    "# interaction_df = pd.DataFrame(interaction_matrix, index=X_train.columns, columns=X_train.columns)\n",
    "# print(interaction_df)\n",
    "interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93dd0326-e46a-45df-90b1-92d142be24a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ctb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roc_curve, auc\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcatboost\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_roc_curve, select_threshold\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m y_pred_proba = \u001b[43mctb\u001b[49m.predict_proba(X_test)[:, \u001b[32m1\u001b[39m] \n\u001b[32m      9\u001b[39m fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba) \n\u001b[32m     10\u001b[39m roc_auc = auc(fpr, tpr)\n",
      "\u001b[31mNameError\u001b[39m: name 'ctb' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from catboost.utils import get_roc_curve, select_threshold\n",
    "\n",
    "y_pred_proba = ctb.predict_proba(X_test)[:, 1] \n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba) \n",
    "roc_auc = auc(fpr, tpr)\n",
    "# Plot the ROC curve\n",
    "plt.figure()  \n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='No Skill')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Breast Cancer Classification')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "catboost_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "\n",
    "\n",
    "\n",
    "roc_curve_values = get_roc_curve(ctb, catboost_pool)\n",
    "\n",
    "boundary = select_threshold(ctb,\n",
    "                            curve=roc_curve_values,\n",
    "                            FPR=0.01)\n",
    "\n",
    "print(\"Boundary:\",boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab789b69-7cf9-436a-bcce-96ab8819c1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_copy['total_chronic_cormodity'] = ((df_test_copy[[        \"OBESIDADE\", \n",
    "                                                        \"RENAL\", \n",
    "                                                        \"CARDIOPATI\",\n",
    "                                                        \"IMUNODEPRE\", \n",
    "                                                        \"DIABETES\", \n",
    "                                                        \"PNEUMOPATI\",\n",
    "                                                        \"HEPATICA\",\n",
    "                                                        #\"SIND_DOWN\"\n",
    "                                                         ]] == 1.0).sum(axis=1))\n",
    "\n",
    "df_test_copy['total_temporary_cormodity'] = (df_test_copy[[       \"FEBRE\",\n",
    "                                                        \"TOSSE\",\n",
    "                                                       # \"PUERPERA\",\n",
    "                                                        \"GARGANTA\",\n",
    "                                                        \"DESC_RESP\",\n",
    "                                                        \"DIARREIA\",\n",
    "                                                         \"VOMITO\",\n",
    "                                                        \"FADIGA\",\n",
    "                                                        \"SATURACAO\",\n",
    "                                                        \"DISPNEIA\"]]== 1.0).sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9da83e64-5971-4c6d-ba28-ea36ae905fcb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lgbm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test_pred = \u001b[43mlgbm\u001b[49m.predict_proba(df_test_copy)[:,\u001b[32m1\u001b[39m]\n\u001b[32m      2\u001b[39m test_pred\n",
      "\u001b[31mNameError\u001b[39m: name 'lgbm' is not defined"
     ]
    }
   ],
   "source": [
    "test_pred = lgbm.predict_proba(df_test_copy)[:,1]\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "632dc4df-2c7e-4132-8b35-2a926c436161",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m pd.DataFrame(np.round(\u001b[43mtest_pred\u001b[49m)).reset_index().to_csv(\u001b[33m'\u001b[39m\u001b[33mresults/lightgbm_less_2_variables.csv\u001b[39m\u001b[33m'\u001b[39m, header=[\u001b[33m'\u001b[39m\u001b[33mID\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mEVOLUCAO\u001b[39m\u001b[33m'\u001b[39m], index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'test_pred' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(np.round(test_pred)).reset_index().to_csv('results/lightgbm_less_2_variables.csv', header=['ID', 'EVOLUCAO'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ffbda0d-68b3-4624-80de-c265d95eb0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 124581 entries, 0 to 124580\n",
      "Data columns (total 33 columns):\n",
      " #   Column                     Non-Null Count   Dtype   \n",
      "---  ------                     --------------   -----   \n",
      " 0   DT_NOTIFIC                 124581 non-null  object  \n",
      " 1   CS_SEXO                    124581 non-null  category\n",
      " 2   CO_RG_RESI                 124581 non-null  category\n",
      " 3   ID_MN_RESI                 124574 non-null  object  \n",
      " 4   CS_ZONA                    124581 non-null  category\n",
      " 5   NU_IDADE_N                 124581 non-null  int64   \n",
      " 6   CS_ESCOL_N                 124581 non-null  category\n",
      " 7   CS_RACA                    124581 non-null  category\n",
      " 8   SG_UF                      124581 non-null  category\n",
      " 9   CS_GESTANT                 124581 non-null  category\n",
      " 10  PUERPERA                   124581 non-null  category\n",
      " 11  DIABETES                   124581 non-null  category\n",
      " 12  PNEUMOPATI                 124581 non-null  category\n",
      " 13  IMUNODEPRE                 124581 non-null  category\n",
      " 14  RENAL                      124581 non-null  category\n",
      " 15  OBESIDADE                  124581 non-null  category\n",
      " 16  OBES_IMC                   124581 non-null  int64   \n",
      " 17  CARDIOPATI                 124581 non-null  category\n",
      " 18  SIND_DOWN                  124581 non-null  category\n",
      " 19  HEPATICA                   124581 non-null  category\n",
      " 20  FATOR_RISC                 124581 non-null  category\n",
      " 21  FEBRE                      124581 non-null  category\n",
      " 22  TOSSE                      124581 non-null  category\n",
      " 23  GARGANTA                   124581 non-null  category\n",
      " 24  DESC_RESP                  124581 non-null  category\n",
      " 25  DIARREIA                   124581 non-null  category\n",
      " 26  VOMITO                     124581 non-null  category\n",
      " 27  FADIGA                     124581 non-null  category\n",
      " 28  SATURACAO                  124581 non-null  category\n",
      " 29  DISPNEIA                   124581 non-null  category\n",
      " 30  VACINA                     124581 non-null  category\n",
      " 31  total_chronic_cormodity    124581 non-null  int64   \n",
      " 32  total_temporary_cormodity  124581 non-null  int64   \n",
      "dtypes: category(27), int64(4), object(2)\n",
      "memory usage: 9.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6ca157-0a51-44f7-a3ff-4489c82a87a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da842ce1-d0c3-49c2-845d-675e1177c654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535d8769-c995-4129-8a0d-7a6f105b36df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def5dba7-bded-465e-9e3f-500711223d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f367fd4-0783-406f-903c-33fbfd62bcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8197b748-ab4c-45ee-9e03-0f91d2b713e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3464d2d8-fd5f-4554-8bca-c0ecb1db70fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9da959-e74c-4fc1-937b-a0ba796c0394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f553b4e-713e-43d9-9003-601791f7a371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b86b07-233c-4be9-a76a-7ff91a29c227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e2089d-a853-4561-9a83-0200cf5fc229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e165f1db-f84b-4946-874f-1176cd263ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef5ca5-3c06-4d12-afdc-db9b2805a88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f0dfd3-11a1-4418-9397-675c090a061f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261b991e-7217-400c-ba7a-d83c9f9044d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e9e34-60ad-4558-8ce4-b7e78ef66e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cead9642-4877-4745-8f71-1e085d7f66cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb360e67-e3c0-4bd4-b161-38685e3afb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb105049-c428-4f28-be78-be6ffeea9ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937c3908-876f-41fe-9245-de660cb1c9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b327e6bc-b823-4138-a15a-16ba1e6b5229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa555d6-9c41-4aab-9864-b6530c357604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cf7831-9426-4bee-823d-f359d21aaecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a485e370-adff-47d3-9ef0-563c27b5b3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a226027-8858-4456-b0a5-bab2b2a6670d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787a38c2-7b68-4b7b-9659-b965599a8a81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
